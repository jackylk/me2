"""æœ¬åœ° Embedding Provider
ä½¿ç”¨ HuggingFace sentence-transformers æ¨¡å‹
"""

from neuromemory.providers.embedding import EmbeddingProvider


class LocalEmbedding(EmbeddingProvider):
    """æœ¬åœ° Embedding Providerï¼Œä½¿ç”¨ sentence-transformers

    æ¨èæ¨¡å‹ï¼š
    - BAAI/bge-small-zh-v1.5 (ä¸­æ–‡ä¼˜åŒ–, 512 dims, ~100MB)
    - BAAI/bge-base-zh-v1.5 (ä¸­æ–‡ä¼˜åŒ–, 768 dims, ~400MB)
    - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (å¤šè¯­è¨€, 384 dims, ~450MB)

    é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/
    """

    def __init__(self, model_name: str = "BAAI/bge-small-zh-v1.5"):
        """åˆå§‹åŒ–æœ¬åœ° Embedding æ¨¡å‹

        Args:
            model_name: HuggingFace æ¨¡å‹åç§°
        """
        try:
            from sentence_transformers import SentenceTransformer
        except ImportError:
            raise ImportError(
                "è¯·å®‰è£… sentence-transformers:\n"
                "pip install sentence-transformers"
            )

        print(f"ğŸ“¥ åŠ è½½ Embedding æ¨¡å‹: {model_name}")
        print("   é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œä¹‹åä»æœ¬åœ°ç¼“å­˜åŠ è½½")

        self._model = SentenceTransformer(model_name)
        self._dims = self._model.get_sentence_embedding_dimension()

        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (ç»´åº¦: {self._dims})")

    @property
    def dims(self) -> int:
        """è¿”å› embedding ç»´åº¦"""
        return self._dims

    async def embed(self, text: str) -> list[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„ embedding

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            embedding å‘é‡
        """
        result = await self.embed_batch([text])
        return result[0]

    async def embed_batch(self, texts: list[str]) -> list[list[float]]:
        """æ‰¹é‡ç”Ÿæˆ embeddings

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            embedding å‘é‡åˆ—è¡¨
        """
        # normalize_embeddings=True ä¼šå½’ä¸€åŒ–å‘é‡ï¼Œä¾¿äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
        embeddings = self._model.encode(
            texts,
            normalize_embeddings=True,
            show_progress_bar=False,  # ä¸æ˜¾ç¤ºè¿›åº¦æ¡
        )
        return [e.tolist() for e in embeddings]
